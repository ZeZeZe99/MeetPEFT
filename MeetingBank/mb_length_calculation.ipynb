{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zejian/miniforge3/envs/learn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Summarize the above article in 2 sentence.\"\n",
    "prompt = \"[INST]{article}\\n{instruction}[/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Yukang/LongAlpaca-7B\"\n",
    "cache_dir = \"../cache\"\n",
    "context_size = 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 15.6MB/s]\n",
      "added_tokens.json: 100%|██████████| 21.0/21.0 [00:00<00:00, 94.1kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 438/438 [00:00<00:00, 1.10MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 25.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "\n",
    "orig_ctx_len = getattr(config, \"max_position_embeddings\", None)\n",
    "if orig_ctx_len and context_size > orig_ctx_len:\n",
    "    scaling_factor = float(math.ceil(context_size / orig_ctx_len))\n",
    "    config.rope_scaling = {\"type\": \"linear\", \"factor\": scaling_factor}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir,\n",
    "    model_max_length=context_size if context_size > orig_ctx_len else orig_ctx_len,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string):\n",
    "    return len(tokenizer.encode(string))\n",
    "\n",
    "def calculate_length(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    source_lengths = []\n",
    "    target_lengths = []\n",
    "    for meeting in tqdm(data):\n",
    "        source_lengths.append(num_tokens_from_string(prompt.format_map({\"article\": meeting['source'], \"instruction\": question})))\n",
    "        target_lengths.append(num_tokens_from_string(meeting['summary']))\n",
    "    return source_lengths, target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_avg(numbers):\n",
    "    min_val = min(numbers)\n",
    "    max_val = max(numbers)\n",
    "    avg_val = sum(numbers) / len(numbers)\n",
    "    return min_val, max_val, avg_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lengths(data0, data1=None):\n",
    "    plt.hist(data0, bins=100, alpha=0.5, color='blue', label='Source')\n",
    "    if data1 is not None:\n",
    "        plt.hist(data1, bins=100, alpha=0.5, color='red', label='Target')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stat(stat):\n",
    "    for task in stat:\n",
    "        print(f'==================== {task} ====================')\n",
    "        source_lengths, target_lengths = stat[task]\n",
    "        total_lengths = [source_lengths[i] + target_lengths[i] for i in range(len(source_lengths))]\n",
    "\n",
    "        # source_min, source_max, source_avg = min_max_avg(source_lengths)\n",
    "        # print(f'{task}-source: min={source_min}, max={source_max}, avg={source_avg}')\n",
    "\n",
    "        # target_min, target_max, target_avg = min_max_avg(target_lengths)\n",
    "        # print(f'{task}-target: min={target_min}, max={target_max}, avg={target_avg}')\n",
    "\n",
    "        total_min, total_max, total_avg = min_max_avg(total_lengths)\n",
    "        print(f'{task}-total: min={total_min}, max={total_max}, avg={total_avg}')\n",
    "        \n",
    "        length_4k = 0\n",
    "        length_8k = 0\n",
    "        length_16k = 0\n",
    "        length_32k = 0\n",
    "        length_above = 0\n",
    "        for l in total_lengths:\n",
    "            if l <= 4000:\n",
    "                length_4k += 1\n",
    "            elif l <= 8000:\n",
    "                length_8k += 1\n",
    "            elif l <= 16000:\n",
    "                length_16k += 1\n",
    "            elif l <= 32000:\n",
    "                length_32k += 1\n",
    "            else:\n",
    "                length_above += 1\n",
    "        print(f'{task}-total: 4k={length_4k}, 8k={length_8k}, 16k={length_16k}, 32k={length_32k}, above={length_above}')\n",
    "\n",
    "        # plot_lengths(source_lengths, target_lengths)\n",
    "        # plot_lengths(total_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 862/862 [00:53<00:00, 16.17it/s]\n",
      "100%|██████████| 861/861 [00:47<00:00, 18.06it/s]\n",
      "100%|██████████| 5169/5169 [05:49<00:00, 14.78it/s]\n"
     ]
    }
   ],
   "source": [
    "stats = dict()\n",
    "for task in ['test', 'validation', 'train']:\n",
    "    path = f'{task}_segment.json'\n",
    "    stats[task] = calculate_length(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== test ====================\n",
      "test-total: min=236, max=96605, avg=4205.548723897912\n",
      "test-total: 4k=631, 8k=123, 16k=69, 32k=27, above=12\n",
      "==================== validation ====================\n",
      "validation-total: min=215, max=87276, avg=4162.984901277584\n",
      "validation-total: 4k=648, 8k=95, 16k=72, 32k=33, above=13\n",
      "==================== train ====================\n",
      "train-total: min=249, max=100985, avg=4638.439736893016\n",
      "train-total: 4k=3666, 8k=730, 16k=436, 32k=240, above=97\n"
     ]
    }
   ],
   "source": [
    "show_stat(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
